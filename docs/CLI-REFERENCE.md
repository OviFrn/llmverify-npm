# CLI Reference

Complete command-line interface documentation for llmverify.

---

## Installation

```bash
# Global install (optional)
npm install -g llmverify

# Or use npx (recommended)
npx llmverify <command>
```

---

## Quick Reference

| Command | Description |
|---------|-------------|
| `llmverify run` | â˜… Master command - run all engines with presets |
| `llmverify wizard` | â˜… Interactive setup wizard |
| `llmverify verify` | Run multi-engine verification (default) |
| `llmverify presets` | List available preset configurations |
| `llmverify benchmark` | Benchmark latency across presets |
| `llmverify engines` | List all verification engines |
| `llmverify explain <engine>` | Explain how an engine works |
| `llmverify adapters` | List available LLM adapters |
| `llmverify doctor` | Check system health |
| `llmverify init` | Initialize config file |
| `llmverify privacy` | Show privacy guarantees |
| `llmverify info` | Show package information |
| `llmverify tutorial` | Show usage examples |
| `llmverify --help` | Show help |
| `llmverify --version` | Show version |

---

## Commands

### `llmverify run` â˜…

Master command that runs all verification engines with preset configurations. **Recommended for most use cases.**

**Usage:**
```bash
llmverify run [content] [options]
```

**Arguments:**
| Argument | Description |
|----------|-------------|
| `content` | Text content to verify (or use --file) |

**Options:**
| Option | Description | Default |
|--------|-------------|---------|
| `-f, --file <path>` | Read content from file | - |
| `-p, --preset <mode>` | Preset mode: dev, prod, strict, fast, ci | dev |
| `--prompt <text>` | Original prompt for classification | - |
| `--input <text>` | User input to check for injection | - |
| `-o, --output <format>` | Output format: text, json, summary | text |
| `--parallel` | Run engines in parallel | true |
| `--no-parallel` | Run engines sequentially | - |

**Presets:**
| Preset | Description | Speed | Thoroughness |
|--------|-------------|-------|--------------|
| `dev` | Development mode - balanced output | â—â—â—â—‹â—‹ | â—â—â—â—â—‹ |
| `prod` | Production mode - optimized for speed | â—â—â—â—â— | â—â—â—â—‹â—‹ |
| `strict` | Strict mode - maximum scrutiny | â—â—â—‹â—‹â—‹ | â—â—â—â—â— |
| `fast` | Fast mode - minimal checks | â—â—â—â—â— | â—â—â—‹â—‹â—‹ |
| `ci` | CI mode - optimized for pipelines | â—â—â—â—â—‹ | â—â—â—â—â—‹ |

**Examples:**
```bash
# Development mode (recommended for starting)
npx llmverify run "Your AI output" --preset dev

# Production mode (fast)
npx llmverify run "Your AI output" --preset prod

# Strict mode with classification
npx llmverify run "AI response" --prompt "Original question" --preset strict

# Check user input for injection
npx llmverify run "AI response" --input "User message" --preset strict

# JSON output for CI/CD
npx llmverify run "Your AI output" --preset ci --output json

# Summary output (one-line)
npx llmverify run "Your AI output" --preset prod --output summary
```

---

### `llmverify wizard` â˜…

Interactive setup wizard for first-time configuration.

**Usage:**
```bash
llmverify wizard
```

**Description:**
Displays a guided walkthrough including:
- Preset selection guide
- Quick start commands
- Programmatic usage examples
- Configuration file setup
- Links to documentation

**Example:**
```bash
npx llmverify wizard
```

---

### `llmverify presets`

List all available preset configurations.

**Usage:**
```bash
llmverify presets [options]
```

**Options:**
| Option | Description |
|--------|-------------|
| `--json` | Output as JSON |

**Example:**
```bash
# Human-readable output
npx llmverify presets

# JSON output
npx llmverify presets --json
```

---

### `llmverify benchmark`

Benchmark verification latency across all presets.

**Usage:**
```bash
llmverify benchmark [options]
```

**Options:**
| Option | Description | Default |
|--------|-------------|---------|
| `-i, --iterations <n>` | Number of iterations per preset | 3 |
| `-c, --content <text>` | Custom content to benchmark | Default test content |
| `--json` | Output results as JSON | false |

**Examples:**
```bash
# Basic benchmark
npx llmverify benchmark

# More iterations for accuracy
npx llmverify benchmark --iterations 10

# Custom content
npx llmverify benchmark --content "Your specific AI output to test"

# JSON output for analysis
npx llmverify benchmark --json
```

---

### `llmverify verify`

Run multi-engine verification on AI output. This is the default command.

**Usage:**
```bash
llmverify verify [content] [options]
llmverify [content] [options]  # 'verify' is default
```

**Arguments:**
| Argument | Description |
|----------|-------------|
| `content` | Text content to verify (or use --file) |

**Options:**
| Option | Description | Default |
|--------|-------------|---------|
| `-f, --file <path>` | Read content from file | - |
| `-j, --json` | Treat content as JSON | false |
| `-c, --config <path>` | Path to config file | - |
| `-v, --verbose` | Verbose output with limitations | false |
| `-o, --output <format>` | Output format: text, json | text |

**Examples:**
```bash
# Basic verification
npx llmverify verify "The capital of France is Paris."

# Verify from file
npx llmverify verify --file response.txt

# JSON output for CI/CD
npx llmverify verify "content" --output json

# Verbose with limitations
npx llmverify verify "content" --verbose

# With custom config
npx llmverify verify "content" --config ./llmverify.config.json

# Verify JSON content
npx llmverify verify --json '{"status": "ok", "data": []}'
```

**Exit Codes:**
| Code | Risk Level | Recommended Action |
|------|------------|-------------------|
| 0 | Low | Allow |
| 1 | Moderate | Review |
| 2 | High/Critical | Block |

**Output (text format):**
```
ğŸ” Running llmverify...

ğŸ“Š Risk Assessment
   Level: LOW
   Score: 12.5%
   Action: allow

ğŸ” Findings
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Severity â”‚ Category â”‚ Message             â”‚ Confidence â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ info     â”‚ pii      â”‚ No PII detected     â”‚ 95%        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“ Interpretation
   Content appears safe with low risk indicators.

Verification ID: abc123
Latency: 45ms | Version: 1.0.0
```

---

### `llmverify engines`

List all verification engines with their current status.

**Usage:**
```bash
llmverify engines [options]
```

**Options:**
| Option | Description |
|--------|-------------|
| `--json` | Output as JSON |

**Example:**
```bash
npx llmverify engines
```

**Output:**
```
ğŸ”§ Verification Engines

  â— classification     enabled    Intent, hallucination, reasoning detection
  â— csm6               enabled    Security checks (PII, harmful content, injection)
  â— hallucination      enabled    Hallucination and factuality detection
  â— drift              enabled    Fingerprint drift analysis
  â—‹ token-rate         disabled   Token rate monitoring (static mode)
  â—‹ latency            disabled   Latency tracking (no wrapping client)
```

---

### `llmverify explain <engine>`

Get detailed explanation of how a specific verification engine works.

**Usage:**
```bash
llmverify explain <engine>
```

**Arguments:**
| Argument | Description |
|----------|-------------|
| `engine` | Engine name: hallucination, classification, csm6, drift |

**Examples:**
```bash
npx llmverify explain hallucination
npx llmverify explain csm6
npx llmverify explain classification
npx llmverify explain drift
```

**Output:**
```
ğŸ” Engine: hallucination

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Detects AI-generated content that may be factually incorrect or fabricated.

Detection Signals:
  â€¢ contradiction signal - conflicting statements within response
  â€¢ low-confidence signal - hedging language patterns
  â€¢ compression signal - information density anomalies
  â€¢ domain mismatch signal - out-of-context claims
  â€¢ pattern mismatch signal - structural inconsistencies
```

---

### `llmverify adapters`

List available LLM provider adapters.

**Usage:**
```bash
llmverify adapters
```

**Output:**
```
ğŸ”Œ Available Adapters

  â— openai       available    OpenAI GPT models
  â— anthropic    available    Anthropic Claude models
  â— langchain    available    LangChain integration
  â—‹ vercel-ai    planned      Vercel AI SDK
  â—‹ ollama       planned      Local Ollama models
```

---

### `llmverify doctor`

Check system health and configuration.

**Usage:**
```bash
llmverify doctor
```

**Output:**
```
ğŸ©º llmverify Doctor

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  âœ“ Node.js Version: v20.10.0
  âœ“ Config File: Found
  â—‹ OPENAI_API_KEY: Not set
  â—‹ ANTHROPIC_API_KEY: Not set
  âœ“ Postinstall: Present

Run "llmverify init" to create a config file.
```

**Checks performed:**
- Node.js version (requires >=18)
- Config file presence
- Environment variables
- Postinstall script

---

### `llmverify init`

Initialize a llmverify configuration file in the current directory.

**Usage:**
```bash
llmverify init
```

**Creates:** `llmverify.config.json`

**Example config:**
```json
{
  "tier": "free",
  "engines": {
    "hallucination": { "enabled": true },
    "consistency": { "enabled": true },
    "jsonValidator": { "enabled": true },
    "csm6": { "enabled": true }
  },
  "performance": {
    "cacheEnabled": true,
    "maxContentLength": 100000
  },
  "output": {
    "verbose": false,
    "includeEvidence": true,
    "includeMethodology": true,
    "includeLimitations": true
  }
}
```

---

### `llmverify privacy`

Display privacy guarantees and data handling policies.

**Usage:**
```bash
llmverify privacy
```

**Output:**
```
ğŸ“‹ llmverify Privacy Guarantees

Free Tier:
  â€¢ Network Traffic: ZERO
  â€¢ Data Transmission: NONE
  â€¢ Telemetry: DISABLED
  â€¢ Verification: Run tcpdump - you will see nothing

Paid Tiers:
  â€¢ Default: LOCAL_PROCESSING
  â€¢ API Calls: OPT_IN_ONLY
  â€¢ Requires: EXPLICIT_API_KEY

We NEVER:
  âœ— No training on user data
  âœ— No third-party data sharing
  âœ— No hidden telemetry
  âœ— No tracking without explicit consent
```

---

### `llmverify info`

Show package information, documentation links, and funding options.

**Usage:**
```bash
llmverify info [options]
```

**Options:**
| Option | Description |
|--------|-------------|
| `--json` | Output as JSON |

**Output:**
```
ğŸ“¦ llmverify Package Information

Package
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Name:        llmverify
  Version:     1.0.0
  Maintainer:  Subodh KC (KingCaliber Labs)

Engines Included
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  âœ“ classification (intent, hallucination, reasoning)
  âœ“ CSM6 (security, PII, harmful content, injection)
  âœ“ hallucination detection
  âœ“ drift analysis
  âœ“ latency monitoring
  âœ“ token-rate tracking

Documentation
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  README     README.md
  CLI        docs/CLI.md
  ENGINES    docs/ENGINES.md
  API        docs/API.md

Privacy
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  ğŸ”’ No telemetry, no remote logging. All analysis local.

Support Development
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â˜• https://www.buymeacoffee.com/subodhkc
```

---

### `llmverify tutorial`

Show usage examples and quick start guide.

**Usage:**
```bash
llmverify tutorial
```

**Output:**
```
ğŸ“š llmverify Quick Start Guide

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. Basic Verification
   Verify AI output directly:
   $ npx llmverify verify "Your AI response here"

2. Verify from File
   Verify content from a file:
   $ npx llmverify verify --file response.txt

3. JSON Output
   Get results as JSON for programmatic use:
   $ npx llmverify verify "content" --output json

4. Initialize Config
   Create a config file for your project:
   $ npx llmverify init

5. Check Engines
   See available verification engines:
   $ npx llmverify engines

6. Learn About Engines
   Understand how detection works:
   $ npx llmverify explain hallucination

7. System Health
   Verify your setup:
   $ npx llmverify doctor

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
For more help: npx llmverify --help
Documentation: https://github.com/subodhkc/llmverify-npm
```

---

## Global Options

These options work with all commands:

| Option | Description |
|--------|-------------|
| `-h, --help` | Show help for command |
| `-V, --version` | Show version number |

---

## Configuration File

Create `llmverify.config.json` in your project root:

```json
{
  "tier": "free",
  "engines": {
    "hallucination": {
      "enabled": true,
      "weights": {
        "speculative": 0.3,
        "overconfident": 0.4,
        "fabricated": 0.3
      }
    },
    "consistency": {
      "enabled": true
    },
    "jsonValidator": {
      "enabled": true,
      "maxRepairSteps": 6
    },
    "csm6": {
      "enabled": true,
      "checks": {
        "security": true,
        "privacy": true,
        "safety": true
      },
      "minSeverity": "low"
    }
  },
  "performance": {
    "cacheEnabled": true,
    "maxContentLength": 100000,
    "timeoutMs": 30000
  },
  "output": {
    "verbose": false,
    "includeEvidence": true,
    "includeMethodology": true,
    "includeLimitations": true
  }
}
```

---

## Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `LLMVERIFY_SILENT` | Suppress postinstall message | false |
| `LLMVERIFY_CONFIG` | Path to config file | ./llmverify.config.json |
| `OPENAI_API_KEY` | OpenAI API key (for adapters) | - |
| `ANTHROPIC_API_KEY` | Anthropic API key (for adapters) | - |

---

## CI/CD Integration

### GitHub Actions

```yaml
- name: Verify AI Output
  run: |
    npx llmverify verify "${{ steps.ai.outputs.response }}" --output json > result.json
    RISK=$(jq -r '.risk.level' result.json)
    if [ "$RISK" = "critical" ] || [ "$RISK" = "high" ]; then
      echo "High risk content detected"
      exit 1
    fi
```

### Exit Code Handling

```bash
#!/bin/bash
npx llmverify verify "$AI_OUTPUT"
EXIT_CODE=$?

case $EXIT_CODE in
  0) echo "âœ“ Low risk - proceeding" ;;
  1) echo "âš  Moderate risk - review required" ;;
  2) echo "âœ— High risk - blocked" && exit 1 ;;
esac
```

---

## Piping and Scripting

```bash
# Pipe content
echo "AI response here" | npx llmverify verify

# From file
cat response.txt | npx llmverify verify

# JSON output to file
npx llmverify verify "content" --output json > result.json

# Extract risk level
RISK=$(npx llmverify verify "content" -o json | jq -r '.risk.level')
```

---

## Troubleshooting

See [TROUBLESHOOTING.md](TROUBLESHOOTING.md) for common errors and solutions.

---

*CLI Reference v1.0.0*
